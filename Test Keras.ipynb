{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying transfer learning\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding layers\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(62, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Model(input = model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range = 30,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=\"img/train/\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"img/valid/\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"img/test/\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "model_final.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=30,\n",
    "                    callbacks = [checkpoint, early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_final.to_json()\n",
    "with open(\"model_image.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save_weights(\"image_model_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save_weights(\"vgg16_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model_image.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "loaded_model.load_weights(\"image_model_weights_2.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=loaded_model.predict_generator(test_generator,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['directory', 'file']] = results.Filename.str.split(\"\\\\\", expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('test_keras.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results.Predictions == results.directory).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.DataFrame(list(labels.values()), columns = ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.to_csv('labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'insta_test/test3.png'\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(150,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(image_path, topk = 10):\n",
    "    time_start = time.clock()\n",
    "    #load model\n",
    "    json_file = open('model_image.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    #load weights\n",
    "    loaded_model.load_weights(\"image_model_weights_2.h5\")\n",
    "    #load labels\n",
    "    df_label = pd.read_csv('labels.csv')\n",
    "    labels = df_label['class'].tolist()\n",
    "    #load and preprocess image\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    x = x/255\n",
    "    preds = loaded_model.predict(x,)\n",
    "    test_list = preds.tolist()\n",
    "    probs = []\n",
    "    for i in test_list:\n",
    "        for j in i:\n",
    "            probs.append(j)\n",
    "    test_df = pd.DataFrame({'label': labels, 'probs': probs})\n",
    "    test_df = test_df.sort_values('probs', ascending = False)[:topk]\n",
    "    labels_use = test_df['label'].tolist()\n",
    "    probs_use = test_df['probs'].tolist()\n",
    "    dict_json = dict()\n",
    "    list_probs = []\n",
    "    for i in range(len(labels_use)):\n",
    "        dict_test = dict()\n",
    "        dict_test['name'] = labels_use[i]\n",
    "        dict_test['probs'] = probs_use[i]\n",
    "        list_probs.append(dict_test)\n",
    "    dict_json['data'] = list_probs\n",
    "    dict_json['time'] = time.clock()-time_start\n",
    "    dict_json = json.dumps(dict_json)\n",
    "    return dict_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": [{\"probs\": 0.7564043998718262, \"name\": \"TRACIE BAG\"}, {\"probs\": 0.052824195474386215, \"name\": \"JAM 8471\"}, {\"probs\": 0.04148963838815689, \"name\": \"LOLI BAG\"}, {\"probs\": 0.029552597552537918, \"name\": \"JAM 8069\"}, {\"probs\": 0.027224337682127953, \"name\": \"KACAMATA 9127\"}, {\"probs\": 0.020686805248260498, \"name\": \"LILBOW BAG\"}, {\"probs\": 0.02042664960026741, \"name\": \"JAM 8191\"}, {\"probs\": 0.009263462387025356, \"name\": \"MORA WALLET\"}, {\"probs\": 0.006083757616579533, \"name\": \"PAULA BAG\"}, {\"probs\": 0.004621386528015137, \"name\": \"JAM MALE 8036\"}], \"time\": 3.3894916906865546}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_use = df['label'].tolist()\n",
    "probs_use = df['probs'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_json = dict()\n",
    "list_probs = []\n",
    "for i in range(len(labels_use)):\n",
    "    dict_test = dict()\n",
    "    dict_test['name'] = labels_use[i]\n",
    "    dict_test['probs'] = probs_use[i]\n",
    "    list_probs.append(dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'TRACIE BAG', 'probs': 0.7564043998718262},\n",
       " {'name': 'JAM 8471', 'probs': 0.052824195474386215},\n",
       " {'name': 'LOLI BAG', 'probs': 0.04148963838815689},\n",
       " {'name': 'JAM 8069', 'probs': 0.029552597552537918},\n",
       " {'name': 'KACAMATA 9127', 'probs': 0.027224337682127953},\n",
       " {'name': 'LILBOW BAG', 'probs': 0.020686805248260498},\n",
       " {'name': 'JAM 8191', 'probs': 0.02042664960026741},\n",
       " {'name': 'MORA WALLET', 'probs': 0.009263462387025356},\n",
       " {'name': 'PAULA BAG', 'probs': 0.006083757616579533},\n",
       " {'name': 'JAM MALE 8036', 'probs': 0.004621386528015137}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_json['data'] = list_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = loaded_model.predict(x,)\n",
    "pred_classes = np.argmax(preds)\n",
    "print(preds)\n",
    "print(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for i in test_list:\n",
    "    for j in i:\n",
    "        probs.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = list(labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'label': test_labels, 'probs': probs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sort_values('probs', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sort_values('probs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Adam\n",
    "Epoch = 10, loss = categorical_crossentropy, metrics = accuracy  \n",
    "loss: 0.9872 - acc: 0.7294 - val_loss: 3.0550 - val_acc: 0.406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
